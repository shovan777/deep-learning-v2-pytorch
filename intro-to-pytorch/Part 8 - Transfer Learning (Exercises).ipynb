{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision. Specifically, you'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
    "\n",
    "ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep neural networks using an architecture called convolutional layers. I'm not going to get into the details of convolutional networks here, but if you want to learn more about them, please [watch this](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
    "\n",
    "Once trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
    "\n",
    "With `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])]) \n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),                                      \n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])]) \n",
    "\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nic/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n",
    "\n",
    "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cpu; Time per batch: 2.712 seconds\n",
      "Device = cuda; Time per batch: 0.005 seconds\n"
     ]
    }
   ],
   "source": [
    "for device in ['cpu', 'cuda']:\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Only train the classifier parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "        # Move input and label tensors to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ii==3:\n",
    "            break\n",
    "        \n",
    "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
    "```python\n",
    "# at beginning of the script\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "...\n",
    "\n",
    "# then whenever you get a new Tensor or Module\n",
    "# this won't copy if they are already on the desired device\n",
    "input = data.to(device)\n",
    "model = MyModule(...).to(device)\n",
    "```\n",
    "\n",
    "From here, I'll let you finish training the model. The process is the same as before except now your model is much more powerful. You should get better than 95% accuracy easily.\n",
    "\n",
    ">**Exercise:** Train a pretrained models to classify the cat and dog images. Continue with the DenseNet model, or try ResNet, it's also a good model to try out first. Make sure you are only training the classifier and the parameters for the features part are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1..  Training Loss: 0.170..  Test Loss: 0.047..  Test Accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 1\n",
    "steps = 0\n",
    "device = 'cuda'\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, labels in testloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1d62c24c50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d6248d908>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 380
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save the model here it is densenet\n",
    "torch.save(model.state_dict(), \"dense121_catdog_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),                                      \n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'test1'\n",
    "test_data = datasets.ImageFolder('test1', transform=submission_transforms)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = 'submit.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9f9709c8442e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# helper.imshow(img[0], normalize=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3099\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3101\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3102\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5129\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5131\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5132\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    620\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    621\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d6212eeb8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 252,
       "width": 262
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = next(iter(testloader))\n",
    "helper.imshow(img[0], normalize=True)\n",
    "# plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        log_ps = model(images)\n",
    "\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        if top_class==1:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = [i for i in range(1, len(pred)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_output=pd.DataFrame({\"id\":id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_output[\"label\"]=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_output.to_csv(\"submission.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
